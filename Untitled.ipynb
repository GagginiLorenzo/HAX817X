{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8534b1f-61c2-43e3-b241-72b47636c601",
   "metadata": {},
   "source": [
    "# A faire du 13/02 au 28/02\n",
    "\n",
    "- Setup l'environement ;\n",
    "- recupéré les données synthétiques ;\n",
    "- coder la methode marginale et tester sur les donée ;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9527d108-9983-44ee-9ae5-a863e5ab4d3d",
   "metadata": {},
   "source": [
    "### Fait du 13 au 18\n",
    "\n",
    "- Explorer la structure algo du repo, quelques points clef resortis :\n",
    "\n",
    "    * Le coeur des calcules pour la parti simulation est fait en R, soit directement avec des packages R, soit par l'emplois de methode en python utiliser via la librairie reticulate.\n",
    "    \n",
    "    * L'environement python est construit via un yaml, pensez pour ètre fournis a conda/mamba forge\n",
    "    \n",
    "    * L'indication fournis pour l'import des librairies R contien une typo importante : install.packages(installedpackages[count]) est une erreur, le nom de la liste est en fait installed_packages\n",
    "    \n",
    "    * Les données généré pour la simulation ne sont directement pas fournis, il faut reffaire tourner la simmulation pour y accédé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad7ae5-fe4e-4733-b3dc-bbe93ddced78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bbd9f87-598b-40c0-8872-6ee88eed55a5",
   "metadata": {},
   "source": [
    "### Fait du 18 au 24 \n",
    "* Setup un environement propre :\n",
    "     - Ne souhaitant pas installé conda sur ma machine, je run un Docker ubuntu avec conda deja setup: https://hub.docker.com/r/condaforge/mambaforge\n",
    "     - une fois le docker en place, j'y installe les utilitaire necessaire et je clone le repo :\n",
    "        * apt update\n",
    "        * apt upgrade\n",
    "        * apt install fish #plus pratique que bash\n",
    "        * fish\n",
    "        * mamba init fish\n",
    "        * apt install software-properties-common\n",
    "        * add-apt-repository ppa:maveonair/helix-editor\n",
    "        * sudo apt update\n",
    "        * sudo apt install helix # mon editeur de code\n",
    "        * apt install r-base-dev\n",
    "        * git clone {https://github.com/achamma723/Group_Variable_Importance} && cd\n",
    "        * mamba env create -f requirements_conda.ym\n",
    "    - Une première difficulter technique significative se présente : le yaml est structuré de façon un peut spécifique, en imposant que certain paquet soit exclusivement installer via pip.\n",
    "    -  Je ne sais pas s'il sagit d'une erreur de configuration, ou une mauvaise manipulation de ma part, mais cette particularité casse l'installation puisque certain de ces paquets ne sont plus a jour sur pip, il faudrait les installer directement via les chanel conda, mais n'ayant pas trouver de bonne syntax yaml pour ce cas spécifique, j'ai fait un script d'installation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c3516d-d8ab-44a3-86f8-d02b84e46ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sys import stdin\n",
    "from os import system\n",
    "from yaml import load, CLoader\n",
    "\n",
    "\n",
    "def get_dependencies(file_in: str) -> list[str]:\n",
    "    data = load(file_in, CLoader)\n",
    "    dependencies = data['dependencies']\n",
    "    pip_dependencies = [each for each in dependencies if 'pip' in each][1]['pip']\n",
    "    return pip_dependencies\n",
    "\n",
    "def install_package(pakagename: str) -> None:\n",
    "    cmd = f'mamba install {pakagename}'\n",
    "    print(cmd)\n",
    "    system(cmd)\n",
    "\n",
    "def main() -> None:\n",
    "    file_in = stdin.read()\n",
    "    data = get_dependencies(file_in)\n",
    "    for package in data:\n",
    "        install_package(package)\n",
    "\n",
    "file_in = stdin.read()\n",
    "deps = get_dependencies(file_in)\n",
    "for pkg in deps:\n",
    "    install_package(pkg)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f598fb7-8ae3-4659-a44d-8c4898ab63c1",
   "metadata": {},
   "source": [
    "une fois l'environement en place, il faut apporté quelque modification au script principal compute_simmulation :\n",
    "* N_CPU <- ifelse(!DEBUG, 100L, 1L) , changer 100L en fonction du nombre de coeur cpu disponible, garder 100L a fait crash ma machine\n",
    "* On peut choisir la liste des methodes a executé, le reste de la structure s'adapte a la taille de la liste, ne garder que methods <- c(\"marginal\") permet de ne faire tourner que la marginal ( la liste compléte initiale de toute les methodes a pris plus de 6h a tourner sur ma machine )\n",
    "* les données synthétiques son stoquer dans la variale sim_data, pour en avoir le csv rajouter une ligne en fin de scripte :\n",
    "    * write.csv(sim_data,\"data.csv\",row.names=FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94a547-1e90-4564-a7a9-591e3c5d6063",
   "metadata": {},
   "source": [
    "### Fait du 25 au 28\n",
    "maintenant qu'on a récupéré les donnée, on peut commencer a coder la methode marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e203b047-49b8-4b78-a208-3be00e263083",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Travaille en cour, pas encore fini !\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "# Read and loads\n",
    "df = pd.read_csv('data.csv')\n",
    "Y=df[\"y\"]\n",
    "X=df.drop(\"y\",axis=1)\n",
    "\n",
    "#random slpit train/pred\n",
    "n = 800 \n",
    "train = X.sample(n, axis=0)\n",
    "\n",
    "indices_in_train = train.index.tolist()\n",
    "pred = X[~X.index.isin(indices_in_train)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8b644-72a0-4798-8d0b-8a6e74ca71ff",
   "metadata": {},
   "source": [
    "# Fait du 28/02 au 03/03\n",
    "\n",
    "#### Affinage du code pour récupéré les donnée,\n",
    "la première methode n'as pas respecter la structure de donnée du scripts, et les donnnées étaient éronnée :\n",
    "- Les fonctions de génération contiennent des valeur par défault, ma methode n'aurais pas du fonctionné, les donné que j'ai pu récupéré était alors issu des valeurs du script par défault.\n",
    "- Je n'avais généré qu'une seul simulation, quand le script en génère 100 \n",
    "- Ma nouvelle, et plus simple methodes, a était d'injecter une instruction d'écriture juste aprés le chargement des données par le scripts\n",
    "- Cette aproche permet de ne rien modifier aux paramettres de la methode, et m'assure de l'intégriter des donnée récupérée\n",
    "- On a désormais accés au 100 tirage de donnée que traite la methodes pour chaqu'un des rho_group tester (0, 0.2, 0.5, 0.8) a rho intra group constant 0.8\n",
    "- voir le script modifier dans le repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a681f6ac-0aee-43c7-a08f-7416998ac798",
   "metadata": {},
   "source": [
    "# Fait du 04/03 au 13/03\n",
    "\n",
    "#### Ecrire les scriptes de vérification des données récupéré :\n",
    " - Un premier scripts teste la matrices d'auto-correlation de chaque groupes, pour chaque simulation\n",
    " - Le resultat pour chaque rho_group est écris directement dans le dossier associé\n",
    " - Un deuxiem scriptes teste pour chaque groupe, les matrices de corrélation associé à chaqu'un des autres groupes, pour chaque simulation\n",
    " - Le resultat pour chaque rho_group est écris directement dans le dossier associé\n",
    "\n",
    "#### Hypothese et resultat\n",
    " - Beaucoup de donnée sont comprise comme non conforme au regarde des ces testes.\n",
    " - Ce faisant, je doute fortement de cette conclusion.\n",
    " - les deux scripts base la conformité des donnée sur la correlation moyenne de chaque groupe et sont écart à la valeur attendue :\n",
    "     * Je ne pense pas que cette aproche soit adapter\n",
    "     * je n'ai pas encore pris le temps de réfléchir a une métrique plus pertinente\n",
    " - Avec ces soucis en tête, j'ai essayer de faire les scripts le plus flexible possible\n",
    " - Je devrais pouvoir accepter tout critère de test, pourvue que les comparaisons soient structurer groupe à groupe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2fe155-70b2-4492-abca-ff3754c78172",
   "metadata": {},
   "source": [
    "# Fait du 13/03 au 20/03\n",
    "#### codé la methode marginale :\n",
    " - Suivant le modèle utilisé dans l'experrience, la methode marginale se donne comme suis :\n",
    "     * Faire une régrétion lineaire généralisé sur chaque groupe\n",
    "     * L'importance marginale du groupe est la somme des coefficients de régression obtenue pour chaque individu du groupe\n",
    "     * Le score est la moyenne par variable du R2 associé a la prédiction de chaque groupe, dans le cas rho_0 où les groupes ne partage pas d'informations, on s'attend a se qu'il soit proche de 0,8/50=0,016\n",
    " - J'ai codé cette methode, voir compute_methode.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a92b5e-3b4d-48bf-831b-121db6210aa4",
   "metadata": {},
   "source": [
    "# Fait du 20/03 au 27/03\n",
    "#### comparé avec la methode original :\n",
    " - J'ai travailler sur rho_0/1.csv\n",
    " - J'ai travailler sur la fonction utilisé dans l'experience pour vérifier mes resultat, voir marginal.R\n",
    " - Je retrouve des resultats similaire à l'experiences, validant pour le moments mon scripte python :\n",
    "[1] \"Applying Marginal Method\"\n",
    "[1] \"y ~ x1+x2+x3+x4+x5\"\n",
    "[1] 0.2724591\n",
    "[1] \"y ~ x6+x7+x8+x9+x10\"\n",
    "[1] 0.5384059\n",
    "[1] \"y ~ x11+x12+x13+x14+x15\"\n",
    "[1] 0.5227941\n",
    "[1] \"y ~ x16+x17+x18+x19+x20\"\n",
    "[1] 0.5205014\n",
    "[1] \"y ~ x21+x22+x23+x24+x25\"\n",
    "[1] 0.8474513\n",
    "[1] \"y ~ x26+x27+x28+x29+x30\"\n",
    "[1] 0.8578651\n",
    "[1] \"y ~ x31+x32+x33+x34+x35\"\n",
    "[1] 0.8583584\n",
    "[1] \"y ~ x36+x37+x38+x39+x40\"\n",
    "[1] 0.8604927\n",
    "[1] \"y ~ x41+x42+x43+x44+x45\"\n",
    "[1] 0.8746681\n",
    "[1] \"y ~ x46+x47+x48+x49+x50\"\n",
    "[1] 0.841207\n",
    "   method  importance      p_value      score\n",
    "1    Marg  2.14790420 3.408590e-10 0.01682414\n",
    "2    Marg -3.06831076 8.876045e-23 0.01682414\n",
    "3    Marg  0.35879303 3.429200e-01 0.01682414\n",
    "4    Marg -0.01619905 9.656091e-01 0.01682414\n",
    "5    Marg -2.37964331 2.961773e-13 0.01682414\n",
    "6    Marg  0.30257080 4.110814e-01 0.01682414\n",
    "7    Marg  0.10475535 7.859355e-01 0.01682414\n",
    "8    Marg  0.14635398 6.924334e-01 0.01682414\n",
    "9    Marg  0.63890036 9.495888e-02 0.01682414\n",
    "10   Marg -0.41221654 2.774437e-01 0.01682414\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
